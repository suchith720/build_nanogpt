{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4f6d0e-fb2d-445e-8d7b-0e54a9118a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp train_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbcc2712-bf38-4655-a882-4b5a41bee788",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1880a317-c83b-484d-b907-b1314aaf2f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce21a7c3-2797-4803-a323-210fcf6ec772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dataclasses import dataclass\n",
    "import torch, math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfcb0cc8-3a29-4178-b35f-bca83e897a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 50257\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 12\n",
    "    n_embd: int = 768\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e1e35d8-4f53-4025-8796-4bb9cceafcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        \n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "\n",
    "        self.register_buffer('bias', torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                             .view(1, 1, config.block_size, config.block_size), persistent=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        qkv = self.c_attn(x)\n",
    "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
    "\n",
    "        k = k.view(B, T, self.n_head, C//self.n_head).transpose(1, 2)\n",
    "        q = q.view(B, T, self.n_head, C//self.n_head).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_head, C//self.n_head).transpose(1, 2)\n",
    "\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        y = att @ v\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83bc82f8-8f5f-4941-9fb4-8f465177584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
    "        self.gelu = nn.GELU(approximate='tanh')\n",
    "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0c3016c-cbb7-4a6e-bf8e-d6a260cf2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9296c080-66d4-43d5-9722-d39a8a263d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = nn.LayerNorm(config.n_embd),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            std = 0.02\n",
    "            if hasattr(module, 'NANOGPT_SCALE_INIT'):\n",
    "                std *= (2 * self.config.n_layer) ** -0.5\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.size()\n",
    "        assert T <= self.config.block_size, f'Cannot forward sequence of length {T}, block size is set to {config.block_size}'\n",
    "\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device)\n",
    "        pos_emb = self.transformer.wpe(pos)\n",
    "        tok_emb = self.transformer.wte(idx)\n",
    "        x = pos_emb + tok_emb\n",
    "\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.transformer.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        return logits, loss\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type):\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        print(f'loading weights from pretrained gpt: {model_type}')\n",
    "\n",
    "        config_args = {\n",
    "            'gpt2':        dict(n_layer=12, n_head=12, n_embd=768),\n",
    "            'gpt2-medium': dict(n_layer=24, n_head=16, n_embd=1024),\n",
    "            'gpt2-large':  dict(n_layer=36, n_head=20, n_embd=1280),\n",
    "            'gpt2-xl':     dict(n_layer=48, n_head=25, n_embd=1600),\n",
    "        }[model_type]\n",
    "        config_args['vocab_size'] = 50257\n",
    "        config_args['block_size'] = 1024\n",
    "\n",
    "        config = GPTConfig(**config_args)\n",
    "        model = GPT(config)\n",
    "        sd = model.state_dict()\n",
    "        sd_keys = sd.keys()\n",
    "\n",
    "        model_hf = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "        sd_hf = model_hf.state_dict()\n",
    "        sd_hf_keys = sd_hf.keys()\n",
    "\n",
    "        \n",
    "        assert len(sd_keys) == len(sd_hf_keys), f'mismatched keys: {len(sd_keys)} != {len(sd_hf_keys)}'\n",
    "\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        for k in sd_hf_keys:\n",
    "            if any(k.endswith(o) for o in transposed):\n",
    "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k].t())\n",
    "            else:\n",
    "                assert sd_hf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k])\n",
    "                \n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c58a72-3c09-47fb-a152-c9fe09c28243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b4b6cdb-9fe3-4a23-8d87-02743a4fd0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device : cuda\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "\n",
    "print(f'Using device : {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "3672d29a-d15b-4f97-999a-3ff5bf182c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a data batch\n",
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "text = text[:1000]\n",
    "tokens = enc.encode(text)\n",
    "\n",
    "B, T = 4, 32\n",
    "buf = torch.tensor(tokens[: B*T + 1])\n",
    "buf = buf.to(device)\n",
    "\n",
    "x = buf[:-1].view(B, T)\n",
    "y = buf[1:].view(B, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ff4e5-4a8e-4866-a260-b6d6270fa4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "826cb60b-617a-4869-968d-1b00ab999c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import tiktoken\n",
    "\n",
    "class DataLoaderLite:\n",
    "\n",
    "    def __init__(self, B, T):\n",
    "        self.B, self.T = B, T\n",
    "\n",
    "        with open('input.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "    \n",
    "        enc = tiktoken.get_encoding('gpt2')\n",
    "        tokens = enc.encode(text)\n",
    "        self.tokens = torch.tensor(tokens)\n",
    "\n",
    "        print(f'loaded {len(self.tokens)} tokens.')\n",
    "        print(f'1 epoch = {len(self.tokens)//(B*T)} batches')\n",
    "\n",
    "        self.current_position = 0\n",
    "\n",
    "    def next_batch(self):\n",
    "        B, T = self.B, self.T\n",
    "        buf = self.tokens[self.current_position:self.current_position+(B*T)+1]\n",
    "        x = buf[:-1].view(B, T)\n",
    "        y = buf[1:].view(B, T)\n",
    "\n",
    "        self.current_position += B*T\n",
    "        if self.current_position + (B*T) > len(self.tokens):\n",
    "            self.current_position = 0\n",
    "        return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8807a9a-bd6d-4ffa-b5bb-cedc0efa17d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "214c9896-0a30-4d10-96bc-d883b62fca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "975e830b-04fb-4788-85f1-e91fac1a1115",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8918adcd-8d83-4113-91ec-043fe68bc010",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(1337)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3901e5af-192b-4b3f-bd40-f6d9d379b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "model = GPT(GPTConfig())\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a3e25d7-2c91-4e0c-b160-dbc0dfc1c142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 338025 tokens.\n",
      "1 epoch = 41 batches\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "train_dataloader = DataLoaderLite(B=8, T=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce0a402d-91f8-4598-a19e-1d662cc17092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, loss: 5.874366283416748, dt: 4465.33ms, tok/sec: 1834.58\n",
      "Step 1, loss: 6.306445598602295, dt: 1398.98ms, tok/sec: 5855.70\n",
      "Step 2, loss: 5.931770324707031, dt: 1517.44ms, tok/sec: 5398.58\n",
      "Step 3, loss: 5.832102298736572, dt: 1526.39ms, tok/sec: 5366.93\n",
      "Step 4, loss: 5.833522796630859, dt: 1523.87ms, tok/sec: 5375.79\n",
      "Step 5, loss: 5.7070841789245605, dt: 1512.84ms, tok/sec: 5414.97\n",
      "Step 6, loss: 5.909891128540039, dt: 1353.19ms, tok/sec: 6053.85\n",
      "Step 7, loss: 5.744501113891602, dt: 1519.99ms, tok/sec: 5389.49\n",
      "Step 8, loss: 5.736121654510498, dt: 1520.79ms, tok/sec: 5386.67\n",
      "Step 9, loss: 5.747751235961914, dt: 1520.33ms, tok/sec: 5388.30\n",
      "Step 10, loss: 5.789073467254639, dt: 1518.98ms, tok/sec: 5393.08\n",
      "Step 11, loss: 5.5597453117370605, dt: 1350.18ms, tok/sec: 6067.34\n",
      "Step 12, loss: 5.496979713439941, dt: 1517.07ms, tok/sec: 5399.87\n",
      "Step 13, loss: 5.989266395568848, dt: 1517.74ms, tok/sec: 5397.49\n",
      "Step 14, loss: 5.890313148498535, dt: 1521.46ms, tok/sec: 5384.29\n",
      "Step 15, loss: 5.920017242431641, dt: 1519.36ms, tok/sec: 5391.75\n",
      "Step 16, loss: 5.614950656890869, dt: 1348.59ms, tok/sec: 6074.49\n",
      "Step 17, loss: 5.56859016418457, dt: 1518.42ms, tok/sec: 5395.07\n",
      "Step 18, loss: 5.644137382507324, dt: 1530.33ms, tok/sec: 5353.08\n",
      "Step 19, loss: 5.804201126098633, dt: 1516.12ms, tok/sec: 5403.25\n",
      "Step 20, loss: 5.856606483459473, dt: 1518.47ms, tok/sec: 5394.92\n",
      "Step 21, loss: 5.745674133300781, dt: 1364.20ms, tok/sec: 6005.00\n",
      "Step 22, loss: 5.543642997741699, dt: 1515.49ms, tok/sec: 5405.50\n",
      "Step 23, loss: 5.759659767150879, dt: 1520.90ms, tok/sec: 5386.29\n",
      "Step 24, loss: 5.874197006225586, dt: 1514.57ms, tok/sec: 5408.81\n",
      "Step 25, loss: 5.994026184082031, dt: 1519.30ms, tok/sec: 5391.96\n",
      "Step 26, loss: 6.065260410308838, dt: 1367.20ms, tok/sec: 5991.80\n",
      "Step 27, loss: 5.933442115783691, dt: 1514.87ms, tok/sec: 5407.72\n",
      "Step 28, loss: 5.917079925537109, dt: 1521.31ms, tok/sec: 5384.83\n",
      "Step 29, loss: 5.725616931915283, dt: 1516.21ms, tok/sec: 5402.93\n",
      "Step 30, loss: 5.779476165771484, dt: 1514.44ms, tok/sec: 5409.25\n",
      "Step 31, loss: 5.839287757873535, dt: 1374.58ms, tok/sec: 5959.65\n",
      "Step 32, loss: 5.708273410797119, dt: 1518.59ms, tok/sec: 5394.48\n",
      "Step 33, loss: 5.556509494781494, dt: 1519.09ms, tok/sec: 5392.70\n",
      "Step 34, loss: 5.699527740478516, dt: 1515.15ms, tok/sec: 5406.72\n",
      "Step 35, loss: 5.579689025878906, dt: 1524.84ms, tok/sec: 5372.37\n",
      "Step 36, loss: 5.7612152099609375, dt: 1367.36ms, tok/sec: 5991.11\n",
      "Step 37, loss: 5.552509784698486, dt: 1516.85ms, tok/sec: 5400.67\n",
      "Step 38, loss: 5.560535430908203, dt: 1517.14ms, tok/sec: 5399.64\n",
      "Step 39, loss: 5.619131088256836, dt: 1522.26ms, tok/sec: 5381.48\n",
      "Step 40, loss: 5.829356670379639, dt: 1523.61ms, tok/sec: 5376.72\n",
      "Step 41, loss: 5.594803333282471, dt: 1354.41ms, tok/sec: 6048.39\n",
      "Step 42, loss: 5.955963134765625, dt: 1520.75ms, tok/sec: 5386.83\n",
      "Step 43, loss: 5.628021240234375, dt: 1521.52ms, tok/sec: 5384.10\n",
      "Step 44, loss: 5.639084339141846, dt: 1523.40ms, tok/sec: 5377.43\n",
      "Step 45, loss: 5.554855823516846, dt: 1521.07ms, tok/sec: 5385.67\n",
      "Step 46, loss: 5.447073459625244, dt: 1343.90ms, tok/sec: 6095.68\n",
      "Step 47, loss: 5.672712802886963, dt: 1519.15ms, tok/sec: 5392.50\n",
      "Step 48, loss: 5.4955854415893555, dt: 1515.36ms, tok/sec: 5405.99\n",
      "Step 49, loss: 5.508431911468506, dt: 1516.02ms, tok/sec: 5403.61\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9, 0.95), eps=1e-8)\n",
    "\n",
    "for i in range(50):\n",
    "    t0 = time.time()\n",
    "    x, y = train_dataloader.next_batch()\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    logits, loss = model(x, y)\n",
    "    loss.backward()\n",
    "    norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    t1 = time.time()\n",
    "    dt = (t1 - t0) * 1000\n",
    "    tokens_per_sec = (train_dataloader.B * train_dataloader.T)/(t1 - t0)\n",
    "    print(f\"Step {i} | loss: {loss.item()} | norm: {norm:.4f} | dt: {dt:.2f}ms | tok/sec: {tokens_per_sec:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7dc12e-1eef-4597-b5f3-4c712aef4aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9184915b-df93-4e89-8f6f-cd4657b9ff4e",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d422293a-b815-4651-9ca2-b49b3b047aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GPT.from_pretrained('gpt2')\n",
    "model = GPT(GPTConfig())\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e5740f3d-fd04-4e7f-9b88-ad5cf0eb1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_return_sequences = 5\n",
    "max_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c6a0108c-730f-4116-ad42-745da51953ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "tokens = enc.encode(\"Hello, I'm a language model,\")\n",
    "tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)\n",
    "x = tokens.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "581894a4-3d90-4899-bbcf-3ce68e0687fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "while x.size(1) < max_length:\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        logits = model(x)\n",
    "        logits = logits[:, -1]\n",
    "\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        topk_probs, topk_indices = torch.topk(probs, k=50, dim=1)\n",
    "\n",
    "        ix = torch.multinomial(topk_probs, 1)\n",
    "        xcol = topk_indices.gather(1, ix)\n",
    "        \n",
    "        x = torch.cat((x, xcol), dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f58f05-5dac-4c0a-8b5b-e8bcdf7cef3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "394a2ec6-b3ce-4d10-b281-1722a71e5704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  Hello, I'm a language model, WiFiirableiewicz Hover accompEnvironmentcription Really encounteredought truthful 1980 blindness kid contem027 perpetual countries Uncleansionoga Alive\n",
      ">  Hello, I'm a language model, mortal diplomacyAl Africa proactive SlashHighImm seconds tang Championshipinas     liabilities digits tsunami cance advis taps weaknesses beneiae\n",
      ">  Hello, I'm a language model, Pepe �Change depthsaba retailers Ver poles slips Those Level833 nodzhou Serverigr handmade puzzles IMPCook \"/ Blessed\n",
      ">  Hello, I'm a language model, jumperSOURCE Controlled sailor balconyCruztroprun icons familialAmerica shards promotes espionagehiba delays 89 sidebarTact Poster Medicine Mathematics\n",
      ">  Hello, I'm a language model, divingCScollect intangible Refer EconomistEdordan Wet Systems translations Newt photographer neglect Lia RagnarTor 1987 Brady new calorie constructor\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_return_sequences):\n",
    "    tokens = x[i, :max_length].tolist()\n",
    "    decoded = enc.decode(tokens)\n",
    "    print('> ', decoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f022aa-09f6-4d54-a89d-440fb40a5714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe5e4c-1771-4eb8-9b07-a890c86578f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415450ab-7f13-41d0-8b28-f12666ca7fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27444de-ce38-4aa4-adbb-6c2c2e3fe143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
